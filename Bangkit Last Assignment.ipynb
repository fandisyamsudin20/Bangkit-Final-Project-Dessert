{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from os import getcwd\n",
    "from PIL import Image\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mikhaeladiputra/Desktop/Bangkit Last Assignment\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "try:\n",
    "    os.mkdir(f\"{getcwd()}/Images\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/apple_pie\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/baklava\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/beignets\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/bread_pudding\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/carrot_cake\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/cheesecake\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/chocolate_cake\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/chocolate_mousse\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/churros\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/creme_brulee\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/cup_cakes\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/donuts\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/frozen_yogurt\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/hummus\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/ice_cream\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/macarons\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/pancakes\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/panna_cotta\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/red_velvet_cake\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/strawberry_shortcake\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/tiramisu\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Training/waffles\")\n",
    "\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/apple_pie\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/baklava\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/beignets\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/bread_pudding\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/carrot_cake\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/cheesecake\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/chocolate_cake\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/chocolate_mousse\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/churros\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/creme_brulee\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/cup_cakes\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/donuts\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/frozen_yogurt\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/hummus\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/ice_cream\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/macarons\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/pancakes\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/panna_cotta\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/red_velvet_cake\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/strawberry_shortcake\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/tiramisu\")\n",
    "    os.mkdir(f\"{getcwd()}/Images/Validation/waffles\")\n",
    "    \n",
    "except OSError as error:\n",
    "    print(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "800\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "BASE_SOURCE_DIR = f\"{getcwd()}/Dataset\"\n",
    "BASE_SOURCE_DIR_IMAGES = f\"{getcwd()}/Images/Training\"\n",
    "BASE_SOURCE_DIR_IMAGES_VAL = f\"{getcwd()}/Images/Validation\"\n",
    "\n",
    "SOURCE_DIR_ARR = [os.path.join(BASE_SOURCE_DIR,'apple_pie'), os.path.join(BASE_SOURCE_DIR,'baklava'), os.path.join(BASE_SOURCE_DIR,'beignets'),\n",
    "                 os.path.join(BASE_SOURCE_DIR,'bread_pudding'), os.path.join(BASE_SOURCE_DIR,'carrot_cake'),os.path.join(BASE_SOURCE_DIR,'cheesecake'),\n",
    "                 os.path.join(BASE_SOURCE_DIR,'chocolate_cake'), os.path.join(BASE_SOURCE_DIR,'chocolate_mousse'), os.path.join(BASE_SOURCE_DIR,'churros'),\n",
    "                 os.path.join(BASE_SOURCE_DIR,'creme_brulee'), os.path.join(BASE_SOURCE_DIR,'cup_cakes'), os.path.join(BASE_SOURCE_DIR,'donuts'),\n",
    "                 os.path.join(BASE_SOURCE_DIR,'frozen_yogurt'), os.path.join(BASE_SOURCE_DIR,'hummus'), os.path.join(BASE_SOURCE_DIR,'ice_cream'),\n",
    "                 os.path.join(BASE_SOURCE_DIR,'macarons'), os.path.join(BASE_SOURCE_DIR,'pancakes'), os.path.join(BASE_SOURCE_DIR,'panna_cotta'),\n",
    "                 os.path.join(BASE_SOURCE_DIR,'red_velvet_cake'),os.path.join(BASE_SOURCE_DIR,'strawberry_shortcake'), os.path.join(BASE_SOURCE_DIR,'tiramisu'), \n",
    "                 os.path.join(BASE_SOURCE_DIR,'waffles')]\n",
    "\n",
    "TRAINING_DIR_ARR = [os.path.join(BASE_SOURCE_DIR_IMAGES,'apple_pie'), os.path.join(BASE_SOURCE_DIR_IMAGES,'baklava'), os.path.join(BASE_SOURCE_DIR_IMAGES,'beignets'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES,'bread_pudding'), os.path.join(BASE_SOURCE_DIR_IMAGES,'carrot_cake'),os.path.join(BASE_SOURCE_DIR_IMAGES,'cheesecake'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES,'chocolate_cake'), os.path.join(BASE_SOURCE_DIR_IMAGES,'chocolate_mousse'), os.path.join(BASE_SOURCE_DIR_IMAGES,'churros'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES,'creme_brulee'), os.path.join(BASE_SOURCE_DIR_IMAGES,'cup_cakes'), os.path.join(BASE_SOURCE_DIR_IMAGES,'donuts'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES,'frozen_yogurt'), os.path.join(BASE_SOURCE_DIR_IMAGES,'hummus'), os.path.join(BASE_SOURCE_DIR_IMAGES,'ice_cream'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES,'macarons'), os.path.join(BASE_SOURCE_DIR_IMAGES,'pancakes'), os.path.join(BASE_SOURCE_DIR_IMAGES,'panna_cotta'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES,'red_velvet_cake'),os.path.join(BASE_SOURCE_DIR_IMAGES,'strawberry_shortcake'), os.path.join(BASE_SOURCE_DIR_IMAGES,'tiramisu'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES,'waffles')]\n",
    "                    \n",
    "TESTING_DIR_ARR = [os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'apple_pie'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'baklava'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'beignets'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'bread_pudding'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'carrot_cake'),os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'cheesecake'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'chocolate_cake'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'chocolate_mousse'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'churros'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'creme_brulee'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'cup_cakes'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'donuts'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'frozen_yogurt'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'hummus'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'ice_cream'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'macarons'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'pancakes'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'panna_cotta'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'red_velvet_cake'),os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'strawberry_shortcake'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'tiramisu'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'waffles')]\n",
    "\n",
    "#MARK - Dividing data method\n",
    "#============================================================================================================\n",
    "#External Params:\n",
    "#Source     : String = Direktori untuk masing\" kelas source, digunakan sebagai tempat foto sebelum di split.\n",
    "#TRAINING   : String = Direktori akhir TRAINING untuk masing\" kelas.\n",
    "#VALIDATION : String = DIrektori AKHIR Testing untuk masing\" Kelas.\n",
    "#SPLIT_SIZE : Double = Menentukan persentase pembagian data source ke 2 directory di atas.\n",
    "#============================================================================================================\n",
    "def divide_data(SOURCE, TRAINING, VALIDATION, SPLIT_SIZE):\n",
    "    \n",
    "    #Creating Limiter\n",
    "    random.sample(SOURCE, len(SOURCE))\n",
    "    SIZE = len(os.listdir(SOURCE))\n",
    "    SPLIT_BOUNDARIES = SIZE * SPLIT_SIZE\n",
    "    SPLIT_BOUNDARIES = round(SPLIT_BOUNDARIES)\n",
    "    \n",
    "    #Copy the divided source files to the training directory\n",
    "    src_training_files = os.listdir(SOURCE)[:SPLIT_BOUNDARIES]\n",
    "    for training_file in src_training_files:\n",
    "        full_training_file = os.path.join(SOURCE,training_file)\n",
    "        if os.path.isfile(full_training_file):\n",
    "            if os.path.getsize(full_training_file)!=0:\n",
    "                destination_dir = shutil.copy(full_training_file,TRAINING)\n",
    "                image = Image.open(destination_dir)\n",
    "                new_image = image.resize((300, 300))\n",
    "                new_image.save(destination_dir)\n",
    "               \n",
    "                \n",
    "    #Copy the divided source files to the training directory           \n",
    "    src_testing = os.listdir(SOURCE)[SPLIT_BOUNDARIES:] \n",
    "    for testing_file in src_testing:\n",
    "        full_testing_file = os.path.join(SOURCE,testing_file)\n",
    "        if os.path.isfile(full_testing_file):\n",
    "            if os.path.getsize(full_testing_file)!=0:\n",
    "                destination_dir = shutil.copy(full_testing_file,VALIDATION)\n",
    "                image = Image.open(destination_dir)\n",
    "                new_image = image.resize((300, 300))\n",
    "                new_image.save(destination_dir)\n",
    "\n",
    "CLASS_SIZE = len(SOURCE_DIR_ARR)\n",
    "SPLIT_SIZE = .8\n",
    "\n",
    "for index in range(CLASS_SIZE):\n",
    "    divide_data(SOURCE_DIR_ARR[index], TRAINING_DIR_ARR[index], TESTING_DIR_ARR[index],SPLIT_SIZE)\n",
    "\n",
    "print(len(os.listdir(SOURCE_DIR_ARR[0])))\n",
    "print(len(os.listdir(TRAINING_DIR_ARR[0])))\n",
    "print(len(os.listdir(TESTING_DIR_ARR[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 22)                138006    \n",
      "=================================================================\n",
      "Total params: 383,030\n",
      "Trainable params: 383,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(None, 298, 298, 16)\n",
      "(None, 149, 149, 16)\n",
      "(None, 147, 147, 32)\n",
      "(None, 73, 73, 32)\n",
      "(None, 71, 71, 64)\n",
      "(None, 35, 35, 64)\n",
      "(None, 33, 33, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 6272)\n",
      "(None, 22)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3), activation='relu', input_shape=(300,300,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(22, activation = 'softmax')\n",
    "])\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()\n",
    "for layer in model.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17600 images belonging to 22 classes.\n",
      "Found 4400 images belonging to 22 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                  rescale=1./255,\n",
    "                  rotation_range=40,\n",
    "                  width_shift_range=0.2,\n",
    "                  height_shift_range=0.2,\n",
    "                  shear_range=0.2,\n",
    "                  zoom_range=0.2,\n",
    "                  horizontal_flip=True,\n",
    "                  fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                  BASE_SOURCE_DIR_IMAGES,  \n",
    "                  target_size=(300, 300),  \n",
    "                  batch_size=10,\n",
    "                  class_mode='categorical'\n",
    "                 )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "                      BASE_SOURCE_DIR_IMAGES_VAL,  \n",
    "                      target_size=(300, 300), \n",
    "                      batch_size=10,\n",
    "                      class_mode='categorical'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "     90/Unknown - 33s 371ms/step - loss: 3.1097 - accuracy: 0.0400"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                     epochs=5,\n",
    "                     verbose=1,\n",
    "                     validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc=history.history['acc']\n",
    "val_acc=history.history['val_acc']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "\n",
    "\n",
    "plt.title('Training and validation loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
