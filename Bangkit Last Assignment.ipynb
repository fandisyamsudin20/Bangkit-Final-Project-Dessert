{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from os import getcwd\n",
    "from PIL import Image\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.getcwd())\n",
    "\n",
    "# try:\n",
    "#     os.mkdir(f\"{getcwd()}/Images\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/apple_pie\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/baklava\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/beignets\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/bread_pudding\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/carrot_cake\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/cheesecake\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/chocolate_cake\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/chocolate_mousse\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/churros\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/creme_brulee\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/cup_cakes\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/donuts\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/frozen_yogurt\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/hummus\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/ice_cream\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/macarons\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/pancakes\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/panna_cotta\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/red_velvet_cake\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/strawberry_shortcake\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/tiramisu\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Training/waffles\")\n",
    "\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/apple_pie\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/baklava\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/beignets\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/bread_pudding\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/carrot_cake\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/cheesecake\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/chocolate_cake\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/chocolate_mousse\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/churros\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/creme_brulee\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/cup_cakes\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/donuts\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/frozen_yogurt\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/hummus\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/ice_cream\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/macarons\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/pancakes\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/panna_cotta\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/red_velvet_cake\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/strawberry_shortcake\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/tiramisu\")\n",
    "#     os.mkdir(f\"{getcwd()}/Images/Validation/waffles\")\n",
    "    \n",
    "# except OSError as error:\n",
    "#     print(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "800\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "BASE_SOURCE_DIR = f\"{getcwd()}/Dataset\"\n",
    "BASE_SOURCE_DIR_IMAGES = f\"{getcwd()}/Images/Training\"\n",
    "BASE_SOURCE_DIR_IMAGES_VAL = f\"{getcwd()}/Images/Validation\"\n",
    "\n",
    "SOURCE_DIR_ARR = [os.path.join(BASE_SOURCE_DIR,'apple_pie'), os.path.join(BASE_SOURCE_DIR,'baklava'), os.path.join(BASE_SOURCE_DIR,'beignets'),\n",
    "                 os.path.join(BASE_SOURCE_DIR,'bread_pudding'), os.path.join(BASE_SOURCE_DIR,'carrot_cake'),os.path.join(BASE_SOURCE_DIR,'cheesecake'),\n",
    "                 os.path.join(BASE_SOURCE_DIR,'chocolate_cake'), os.path.join(BASE_SOURCE_DIR,'chocolate_mousse'), os.path.join(BASE_SOURCE_DIR,'churros'),\n",
    "                 os.path.join(BASE_SOURCE_DIR,'creme_brulee'), os.path.join(BASE_SOURCE_DIR,'cup_cakes'), os.path.join(BASE_SOURCE_DIR,'donuts'),\n",
    "                 os.path.join(BASE_SOURCE_DIR,'frozen_yogurt'), os.path.join(BASE_SOURCE_DIR,'hummus'), os.path.join(BASE_SOURCE_DIR,'ice_cream'),\n",
    "                 os.path.join(BASE_SOURCE_DIR,'macarons'), os.path.join(BASE_SOURCE_DIR,'pancakes'), os.path.join(BASE_SOURCE_DIR,'panna_cotta'),\n",
    "                 os.path.join(BASE_SOURCE_DIR,'red_velvet_cake'),os.path.join(BASE_SOURCE_DIR,'strawberry_shortcake'), os.path.join(BASE_SOURCE_DIR,'tiramisu'), \n",
    "                 os.path.join(BASE_SOURCE_DIR,'waffles')]\n",
    "\n",
    "TRAINING_DIR_ARR = [os.path.join(BASE_SOURCE_DIR_IMAGES,'apple_pie'), os.path.join(BASE_SOURCE_DIR_IMAGES,'baklava'), os.path.join(BASE_SOURCE_DIR_IMAGES,'beignets'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES,'bread_pudding'), os.path.join(BASE_SOURCE_DIR_IMAGES,'carrot_cake'),os.path.join(BASE_SOURCE_DIR_IMAGES,'cheesecake'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES,'chocolate_cake'), os.path.join(BASE_SOURCE_DIR_IMAGES,'chocolate_mousse'), os.path.join(BASE_SOURCE_DIR_IMAGES,'churros'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES,'creme_brulee'), os.path.join(BASE_SOURCE_DIR_IMAGES,'cup_cakes'), os.path.join(BASE_SOURCE_DIR_IMAGES,'donuts'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES,'frozen_yogurt'), os.path.join(BASE_SOURCE_DIR_IMAGES,'hummus'), os.path.join(BASE_SOURCE_DIR_IMAGES,'ice_cream'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES,'macarons'), os.path.join(BASE_SOURCE_DIR_IMAGES,'pancakes'), os.path.join(BASE_SOURCE_DIR_IMAGES,'panna_cotta'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES,'red_velvet_cake'),os.path.join(BASE_SOURCE_DIR_IMAGES,'strawberry_shortcake'), os.path.join(BASE_SOURCE_DIR_IMAGES,'tiramisu'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES,'waffles')]\n",
    "                    \n",
    "TESTING_DIR_ARR = [os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'apple_pie'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'baklava'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'beignets'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'bread_pudding'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'carrot_cake'),os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'cheesecake'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'chocolate_cake'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'chocolate_mousse'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'churros'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'creme_brulee'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'cup_cakes'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'donuts'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'frozen_yogurt'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'hummus'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'ice_cream'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'macarons'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'pancakes'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'panna_cotta'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'red_velvet_cake'),os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'strawberry_shortcake'), os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'tiramisu'),\n",
    "                 os.path.join(BASE_SOURCE_DIR_IMAGES_VAL,'waffles')]\n",
    "\n",
    "#MARK - Dividing data method\n",
    "#============================================================================================================\n",
    "#External Params:\n",
    "#Source     : String = Direktori untuk masing\" kelas source, digunakan sebagai tempat foto sebelum di split.\n",
    "#TRAINING   : String = Direktori akhir TRAINING untuk masing\" kelas.\n",
    "#VALIDATION : String = DIrektori AKHIR Testing untuk masing\" Kelas.\n",
    "#SPLIT_SIZE : Double = Menentukan persentase pembagian data source ke 2 directory di atas.\n",
    "#============================================================================================================\n",
    "def divide_data(SOURCE, TRAINING, VALIDATION, SPLIT_SIZE):\n",
    "    \n",
    "    #Creating Limiter\n",
    "    random.sample(SOURCE, len(SOURCE))\n",
    "    SIZE = len(os.listdir(SOURCE))\n",
    "    SPLIT_BOUNDARIES = SIZE * SPLIT_SIZE\n",
    "    SPLIT_BOUNDARIES = round(SPLIT_BOUNDARIES)\n",
    "    \n",
    "    #Copy the divided source files to the training directory\n",
    "    src_training_files = os.listdir(SOURCE)[:SPLIT_BOUNDARIES]\n",
    "    for training_file in src_training_files:\n",
    "        full_training_file = os.path.join(SOURCE,training_file)\n",
    "        if os.path.isfile(full_training_file):\n",
    "            if os.path.getsize(full_training_file)!=0:\n",
    "                destination_dir = shutil.copy(full_training_file,TRAINING)\n",
    "                image = Image.open(destination_dir)\n",
    "                new_image = image.resize((300, 300))\n",
    "                new_image.save(destination_dir)\n",
    "               \n",
    "                \n",
    "    #Copy the divided source files to the training directory           \n",
    "    src_testing = os.listdir(SOURCE)[SPLIT_BOUNDARIES:] \n",
    "    for testing_file in src_testing:\n",
    "        full_testing_file = os.path.join(SOURCE,testing_file)\n",
    "        if os.path.isfile(full_testing_file):\n",
    "            if os.path.getsize(full_testing_file)!=0:\n",
    "                destination_dir = shutil.copy(full_testing_file,VALIDATION)\n",
    "                image = Image.open(destination_dir)\n",
    "                new_image = image.resize((300, 300))\n",
    "                new_image.save(destination_dir)\n",
    "\n",
    "CLASS_SIZE = len(SOURCE_DIR_ARR)\n",
    "SPLIT_SIZE = .8\n",
    "\n",
    "for index in range(CLASS_SIZE):\n",
    "    divide_data(SOURCE_DIR_ARR[index], TRAINING_DIR_ARR[index], TESTING_DIR_ARR[index],SPLIT_SIZE)\n",
    "\n",
    "print(len(os.listdir(SOURCE_DIR_ARR[0])))\n",
    "print(len(os.listdir(TRAINING_DIR_ARR[0])))\n",
    "print(len(os.listdir(TESTING_DIR_ARR[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 78400)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               20070656  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 22)                11286     \n",
      "=================================================================\n",
      "Total params: 20,237,110\n",
      "Trainable params: 20,237,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(None, 298, 298, 16)\n",
      "(None, 149, 149, 16)\n",
      "(None, 147, 147, 32)\n",
      "(None, 73, 73, 32)\n",
      "(None, 71, 71, 64)\n",
      "(None, 35, 35, 64)\n",
      "(None, 78400)\n",
      "(None, 256)\n",
      "(None, 512)\n",
      "(None, 22)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,(3,3), padding = 'same', activation='relu', input_shape=(300,300,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3), padding = 'same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3), padding = 'same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(22, activation = 'softmax')\n",
    "])\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "for layer in model.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17600 images belonging to 22 classes.\n",
      "Found 4400 images belonging to 22 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                   rotation_range = 40,\n",
    "                   width_shift_range = 0.2,\n",
    "                   height_shift_range = 0.2,\n",
    "                   shear_range = 0.2,\n",
    "                   zoom_range = 0.2,\n",
    "                   horizontal_flip = True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                  BASE_SOURCE_DIR_IMAGES,  \n",
    "                  target_size=(300, 300),  \n",
    "                  batch_size=100,\n",
    "                  class_mode='categorical'\n",
    "                 )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                      BASE_SOURCE_DIR_IMAGES_VAL,  \n",
    "                      target_size=(300, 300), \n",
    "                      batch_size=100,\n",
    "                      class_mode='categorical'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "176/176 [==============================] - 646s 4s/step - loss: 3.0327 - accuracy: 0.0890 - val_loss: 2.9118 - val_accuracy: 0.1284\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 649s 4s/step - loss: 2.8429 - accuracy: 0.1476 - val_loss: 2.8034 - val_accuracy: 0.1630\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 658s 4s/step - loss: 2.7594 - accuracy: 0.1656 - val_loss: 2.7369 - val_accuracy: 0.1798\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 645s 4s/step - loss: 2.6955 - accuracy: 0.1841 - val_loss: 2.6624 - val_accuracy: 0.1993\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 641s 4s/step - loss: 2.6344 - accuracy: 0.2012 - val_loss: 2.6426 - val_accuracy: 0.2032\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 639s 4s/step - loss: 2.5746 - accuracy: 0.2173 - val_loss: 2.5784 - val_accuracy: 0.2157\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 638s 4s/step - loss: 2.5259 - accuracy: 0.2326 - val_loss: 2.5437 - val_accuracy: 0.2361\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 637s 4s/step - loss: 2.4773 - accuracy: 0.2503 - val_loss: 2.5095 - val_accuracy: 0.2466\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 640s 4s/step - loss: 2.4275 - accuracy: 0.2586 - val_loss: 2.5409 - val_accuracy: 0.2441\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 637s 4s/step - loss: 2.3962 - accuracy: 0.2765 - val_loss: 2.4194 - val_accuracy: 0.2732\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 637s 4s/step - loss: 2.3467 - accuracy: 0.2866 - val_loss: 2.4391 - val_accuracy: 0.2707\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 637s 4s/step - loss: 2.3010 - accuracy: 0.3009 - val_loss: 2.3702 - val_accuracy: 0.2895\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 637s 4s/step - loss: 2.2891 - accuracy: 0.3072 - val_loss: 2.4049 - val_accuracy: 0.2725\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 638s 4s/step - loss: 2.2548 - accuracy: 0.3152 - val_loss: 2.3643 - val_accuracy: 0.2861\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 637s 4s/step - loss: 2.2027 - accuracy: 0.3286 - val_loss: 2.3193 - val_accuracy: 0.2939\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 636s 4s/step - loss: 2.1791 - accuracy: 0.3364 - val_loss: 2.2807 - val_accuracy: 0.3193\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 637s 4s/step - loss: 2.1588 - accuracy: 0.3462 - val_loss: 2.2748 - val_accuracy: 0.3195\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 637s 4s/step - loss: 2.1121 - accuracy: 0.3611 - val_loss: 2.2660 - val_accuracy: 0.3250\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 636s 4s/step - loss: 2.0907 - accuracy: 0.3689 - val_loss: 2.2553 - val_accuracy: 0.3239\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 637s 4s/step - loss: 2.0595 - accuracy: 0.3728 - val_loss: 2.2094 - val_accuracy: 0.3364\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 636s 4s/step - loss: 2.0423 - accuracy: 0.3774 - val_loss: 2.2246 - val_accuracy: 0.3323\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 637s 4s/step - loss: 2.0230 - accuracy: 0.3828 - val_loss: 2.2055 - val_accuracy: 0.3330\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 635s 4s/step - loss: 1.9912 - accuracy: 0.3916 - val_loss: 2.1838 - val_accuracy: 0.3468\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 636s 4s/step - loss: 1.9655 - accuracy: 0.3998 - val_loss: 2.1758 - val_accuracy: 0.3507\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 640s 4s/step - loss: 1.9424 - accuracy: 0.4034 - val_loss: 2.1613 - val_accuracy: 0.3548\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 636s 4s/step - loss: 1.9230 - accuracy: 0.4082 - val_loss: 2.1721 - val_accuracy: 0.3423\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 637s 4s/step - loss: 1.9127 - accuracy: 0.4113 - val_loss: 2.1343 - val_accuracy: 0.3595\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 636s 4s/step - loss: 1.8951 - accuracy: 0.4166 - val_loss: 2.1661 - val_accuracy: 0.3609\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 636s 4s/step - loss: 1.8741 - accuracy: 0.4276 - val_loss: 2.1241 - val_accuracy: 0.3645\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 638s 4s/step - loss: 1.8465 - accuracy: 0.4377 - val_loss: 2.1380 - val_accuracy: 0.3620\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 639s 4s/step - loss: 1.8345 - accuracy: 0.4374 - val_loss: 2.1307 - val_accuracy: 0.3630\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 638s 4s/step - loss: 1.8270 - accuracy: 0.4413 - val_loss: 2.1441 - val_accuracy: 0.3702\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 638s 4s/step - loss: 1.7864 - accuracy: 0.4515 - val_loss: 2.1640 - val_accuracy: 0.3602\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 639s 4s/step - loss: 1.7925 - accuracy: 0.4520 - val_loss: 2.1589 - val_accuracy: 0.3645\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 639s 4s/step - loss: 1.7655 - accuracy: 0.4530 - val_loss: 2.1659 - val_accuracy: 0.3734\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 638s 4s/step - loss: 1.7569 - accuracy: 0.4586 - val_loss: 2.1989 - val_accuracy: 0.3648\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 638s 4s/step - loss: 1.7497 - accuracy: 0.4598 - val_loss: 2.1815 - val_accuracy: 0.3693\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 639s 4s/step - loss: 1.7136 - accuracy: 0.4766 - val_loss: 2.1394 - val_accuracy: 0.3782\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 639s 4s/step - loss: 1.6958 - accuracy: 0.4738 - val_loss: 2.1237 - val_accuracy: 0.3918\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 640s 4s/step - loss: 1.6850 - accuracy: 0.4809 - val_loss: 2.1576 - val_accuracy: 0.3807\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 638s 4s/step - loss: 1.6843 - accuracy: 0.4850 - val_loss: 2.1668 - val_accuracy: 0.3755\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 638s 4s/step - loss: 1.6950 - accuracy: 0.4746 - val_loss: 2.1135 - val_accuracy: 0.3814\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 638s 4s/step - loss: 1.6553 - accuracy: 0.4872 - val_loss: 2.1018 - val_accuracy: 0.3805\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 637s 4s/step - loss: 1.6504 - accuracy: 0.4877 - val_loss: 2.1153 - val_accuracy: 0.3818\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 640s 4s/step - loss: 1.6139 - accuracy: 0.4956 - val_loss: 2.1292 - val_accuracy: 0.3859\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 639s 4s/step - loss: 1.6139 - accuracy: 0.4983 - val_loss: 2.2122 - val_accuracy: 0.3655\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 644s 4s/step - loss: 1.6094 - accuracy: 0.4964 - val_loss: 2.1331 - val_accuracy: 0.3916\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 650s 4s/step - loss: 1.6093 - accuracy: 0.5019 - val_loss: 2.1439 - val_accuracy: 0.3807\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 652s 4s/step - loss: 1.5885 - accuracy: 0.5041 - val_loss: 2.1348 - val_accuracy: 0.3907\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 654s 4s/step - loss: 1.5956 - accuracy: 0.5046 - val_loss: 2.1906 - val_accuracy: 0.3898\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 655s 4s/step - loss: 1.5577 - accuracy: 0.5127 - val_loss: 2.1649 - val_accuracy: 0.3895\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 655s 4s/step - loss: 1.5689 - accuracy: 0.5136 - val_loss: 2.1649 - val_accuracy: 0.3943\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 662s 4s/step - loss: 1.5543 - accuracy: 0.5107 - val_loss: 2.1728 - val_accuracy: 0.3859\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 648s 4s/step - loss: 1.5263 - accuracy: 0.5260 - val_loss: 2.1848 - val_accuracy: 0.3927\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 674s 4s/step - loss: 1.5320 - accuracy: 0.5215 - val_loss: 2.1473 - val_accuracy: 0.3925\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 691s 4s/step - loss: 1.5043 - accuracy: 0.5294 - val_loss: 2.2104 - val_accuracy: 0.3870\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 683s 4s/step - loss: 1.5210 - accuracy: 0.5267 - val_loss: 2.1661 - val_accuracy: 0.4061\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 686s 4s/step - loss: 1.5148 - accuracy: 0.5282 - val_loss: 2.1725 - val_accuracy: 0.3830\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 694s 4s/step - loss: 1.4754 - accuracy: 0.5387 - val_loss: 2.1859 - val_accuracy: 0.3923\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 695s 4s/step - loss: 1.4707 - accuracy: 0.5401 - val_loss: 2.1999 - val_accuracy: 0.3843\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 693s 4s/step - loss: 1.4674 - accuracy: 0.5410 - val_loss: 2.2110 - val_accuracy: 0.3936\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 696s 4s/step - loss: 1.4545 - accuracy: 0.5455 - val_loss: 2.2644 - val_accuracy: 0.3880\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 693s 4s/step - loss: 1.4455 - accuracy: 0.5484 - val_loss: 2.2400 - val_accuracy: 0.4005\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 694s 4s/step - loss: 1.4526 - accuracy: 0.5456 - val_loss: 2.2527 - val_accuracy: 0.3870\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 688s 4s/step - loss: 1.4401 - accuracy: 0.5465 - val_loss: 2.2306 - val_accuracy: 0.3798\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 685s 4s/step - loss: 1.4252 - accuracy: 0.5551 - val_loss: 2.2982 - val_accuracy: 0.3664\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 705s 4s/step - loss: 1.4312 - accuracy: 0.5522 - val_loss: 2.2594 - val_accuracy: 0.3920\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 716s 4s/step - loss: 1.4316 - accuracy: 0.5489 - val_loss: 2.2231 - val_accuracy: 0.3902\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 716s 4s/step - loss: 1.4004 - accuracy: 0.5590 - val_loss: 2.2785 - val_accuracy: 0.3820\n",
      "Epoch 70/100\n",
      " 41/176 [=====>........................] - ETA: 8:01 - loss: 1.3498 - accuracy: 0.5720"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                     epochs=100,\n",
    "                     verbose=1,\n",
    "                     validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc=history.history['acc']\n",
    "val_acc=history.history['val_acc']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "\n",
    "\n",
    "plt.title('Training and validation loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
